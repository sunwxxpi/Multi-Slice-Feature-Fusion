=======================================================================================================================================
Layer (type (var_name):depth-idx)                       Input Shape          Kernel Shape         Output Shape         Param %
=======================================================================================================================================
Unet (Unet)                                             [4, 1, 512, 512]     --                   [4, 5, 512, 512]          --
├─MixVisionTransformerEncoder (encoder): 1-1            [4, 1, 512, 512]     --                   [4, 1, 512, 512]          --
│    └─OverlapPatchEmbed (patch_embed1): 2-1            [4, 1, 512, 512]     --                   [4, 64, 128, 128]         --
│    │    └─Conv2d (proj): 3-1                          [4, 1, 512, 512]     [7, 7]               [4, 64, 128, 128]      0.01%
│    │    └─LayerNorm (norm): 3-2                       [4, 64, 128, 128]    --                   [4, 64, 128, 128]      0.00%
│    └─Sequential (block1): 2-2                         [4, 64, 128, 128]    --                   [4, 64, 128, 128]         --
│    │    └─Block (0): 3-3                              [4, 64, 128, 128]    --                   [4, 64, 128, 128]         --
│    │    │    └─LayerNorm (norm1): 4-1                 [4, 16384, 64]       --                   [4, 16384, 64]         0.00%
│    │    │    └─Attention (attn): 4-2                  [4, 16384, 64]       --                   [4, 16384, 64]            --
│    │    │    │    └─Linear (q): 5-1                   [4, 16384, 64]       --                   [4, 16384, 64]         0.02%
│    │    │    │    └─Conv2d (sr): 5-2                  [4, 64, 128, 128]    [8, 8]               [4, 64, 16, 16]        0.95%
│    │    │    │    └─LayerNorm (norm): 5-3             [4, 256, 64]         --                   [4, 256, 64]           0.00%
│    │    │    │    └─Linear (kv): 5-4                  [4, 256, 64]         --                   [4, 256, 128]          0.03%
│    │    │    │    └─Dropout (attn_drop): 5-5          [4, 1, 16384, 256]   --                   [4, 1, 16384, 256]        --
│    │    │    │    └─Linear (proj): 5-6                [4, 16384, 64]       --                   [4, 16384, 64]         0.02%
│    │    │    │    └─Dropout (proj_drop): 5-7          [4, 16384, 64]       --                   [4, 16384, 64]            --
│    │    │    └─Identity (drop_path): 4-3              [4, 16384, 64]       --                   [4, 16384, 64]            --
│    │    │    └─LayerNorm (norm2): 4-4                 [4, 16384, 64]       --                   [4, 16384, 64]         0.00%
│    │    │    └─Mlp (mlp): 4-5                         [4, 16384, 64]       --                   [4, 16384, 64]            --
│    │    │    │    └─Linear (fc1): 5-8                 [4, 16384, 64]       --                   [4, 16384, 256]        0.06%
│    │    │    │    └─DWConv (dwconv): 5-9              [4, 16384, 256]      --                   [4, 16384, 256]        0.01%
│    │    │    │    └─GELU (act): 5-10                  [4, 16384, 256]      --                   [4, 16384, 256]           --
│    │    │    │    └─Dropout (drop): 5-11              [4, 16384, 256]      --                   [4, 16384, 256]           --
│    │    │    │    └─Linear (fc2): 5-12                [4, 16384, 256]      --                   [4, 16384, 64]         0.06%
│    │    │    │    └─Dropout (drop): 5-13              [4, 16384, 64]       --                   [4, 16384, 64]       (recursive)
│    │    │    └─Identity (drop_path): 4-6              [4, 16384, 64]       --                   [4, 16384, 64]       (recursive)
│    │    └─Block (1): 3-4                              [4, 64, 128, 128]    --                   [4, 64, 128, 128]         --
│    │    │    └─LayerNorm (norm1): 4-7                 [4, 16384, 64]       --                   [4, 16384, 64]         0.00%
│    │    │    └─Attention (attn): 4-8                  [4, 16384, 64]       --                   [4, 16384, 64]            --
│    │    │    │    └─Linear (q): 5-14                  [4, 16384, 64]       --                   [4, 16384, 64]         0.02%
│    │    │    │    └─Conv2d (sr): 5-15                 [4, 64, 128, 128]    [8, 8]               [4, 64, 16, 16]        0.95%
│    │    │    │    └─LayerNorm (norm): 5-16            [4, 256, 64]         --                   [4, 256, 64]           0.00%
│    │    │    │    └─Linear (kv): 5-17                 [4, 256, 64]         --                   [4, 256, 128]          0.03%
│    │    │    │    └─Dropout (attn_drop): 5-18         [4, 1, 16384, 256]   --                   [4, 1, 16384, 256]        --
│    │    │    │    └─Linear (proj): 5-19               [4, 16384, 64]       --                   [4, 16384, 64]         0.02%
│    │    │    │    └─Dropout (proj_drop): 5-20         [4, 16384, 64]       --                   [4, 16384, 64]            --
│    │    │    └─DropPath (drop_path): 4-9              [4, 16384, 64]       --                   [4, 16384, 64]            --
│    │    │    └─LayerNorm (norm2): 4-10                [4, 16384, 64]       --                   [4, 16384, 64]         0.00%
│    │    │    └─Mlp (mlp): 4-11                        [4, 16384, 64]       --                   [4, 16384, 64]            --
│    │    │    │    └─Linear (fc1): 5-21                [4, 16384, 64]       --                   [4, 16384, 256]        0.06%
│    │    │    │    └─DWConv (dwconv): 5-22             [4, 16384, 256]      --                   [4, 16384, 256]        0.01%
│    │    │    │    └─GELU (act): 5-23                  [4, 16384, 256]      --                   [4, 16384, 256]           --
│    │    │    │    └─Dropout (drop): 5-24              [4, 16384, 256]      --                   [4, 16384, 256]           --
│    │    │    │    └─Linear (fc2): 5-25                [4, 16384, 256]      --                   [4, 16384, 64]         0.06%
│    │    │    │    └─Dropout (drop): 5-26              [4, 16384, 64]       --                   [4, 16384, 64]       (recursive)
│    │    │    └─DropPath (drop_path): 4-12             [4, 16384, 64]       --                   [4, 16384, 64]       (recursive)
│    │    └─Block (2): 3-5                              [4, 64, 128, 128]    --                   [4, 64, 128, 128]         --
│    │    │    └─LayerNorm (norm1): 4-13                [4, 16384, 64]       --                   [4, 16384, 64]         0.00%
│    │    │    └─Attention (attn): 4-14                 [4, 16384, 64]       --                   [4, 16384, 64]            --
│    │    │    │    └─Linear (q): 5-27                  [4, 16384, 64]       --                   [4, 16384, 64]         0.02%
│    │    │    │    └─Conv2d (sr): 5-28                 [4, 64, 128, 128]    [8, 8]               [4, 64, 16, 16]        0.95%
│    │    │    │    └─LayerNorm (norm): 5-29            [4, 256, 64]         --                   [4, 256, 64]           0.00%
│    │    │    │    └─Linear (kv): 5-30                 [4, 256, 64]         --                   [4, 256, 128]          0.03%
│    │    │    │    └─Dropout (attn_drop): 5-31         [4, 1, 16384, 256]   --                   [4, 1, 16384, 256]        --
│    │    │    │    └─Linear (proj): 5-32               [4, 16384, 64]       --                   [4, 16384, 64]         0.02%
│    │    │    │    └─Dropout (proj_drop): 5-33         [4, 16384, 64]       --                   [4, 16384, 64]            --
│    │    │    └─DropPath (drop_path): 4-15             [4, 16384, 64]       --                   [4, 16384, 64]            --
│    │    │    └─LayerNorm (norm2): 4-16                [4, 16384, 64]       --                   [4, 16384, 64]         0.00%
│    │    │    └─Mlp (mlp): 4-17                        [4, 16384, 64]       --                   [4, 16384, 64]            --
│    │    │    │    └─Linear (fc1): 5-34                [4, 16384, 64]       --                   [4, 16384, 256]        0.06%
│    │    │    │    └─DWConv (dwconv): 5-35             [4, 16384, 256]      --                   [4, 16384, 256]        0.01%
│    │    │    │    └─GELU (act): 5-36                  [4, 16384, 256]      --                   [4, 16384, 256]           --
│    │    │    │    └─Dropout (drop): 5-37              [4, 16384, 256]      --                   [4, 16384, 256]           --
│    │    │    │    └─Linear (fc2): 5-38                [4, 16384, 256]      --                   [4, 16384, 64]         0.06%
│    │    │    │    └─Dropout (drop): 5-39              [4, 16384, 64]       --                   [4, 16384, 64]       (recursive)
│    │    │    └─DropPath (drop_path): 4-18             [4, 16384, 64]       --                   [4, 16384, 64]       (recursive)
│    └─LayerNorm (norm1): 2-3                           [4, 64, 128, 128]    --                   [4, 64, 128, 128]      0.00%
│    └─OverlapPatchEmbed (patch_embed2): 2-4            [4, 64, 128, 128]    --                   [4, 128, 64, 64]          --
│    │    └─Conv2d (proj): 3-6                          [4, 64, 128, 128]    [3, 3]               [4, 128, 64, 64]       0.27%
│    │    └─LayerNorm (norm): 3-7                       [4, 128, 64, 64]     --                   [4, 128, 64, 64]       0.00%
│    └─Sequential (block2): 2-5                         [4, 128, 64, 64]     --                   [4, 128, 64, 64]          --
│    │    └─Block (0): 3-8                              [4, 128, 64, 64]     --                   [4, 128, 64, 64]          --
│    │    │    └─LayerNorm (norm1): 4-19                [4, 4096, 128]       --                   [4, 4096, 128]         0.00%
│    │    │    └─Attention (attn): 4-20                 [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    │    └─Linear (q): 5-40                  [4, 4096, 128]       --                   [4, 4096, 128]         0.06%
│    │    │    │    └─Conv2d (sr): 5-41                 [4, 128, 64, 64]     [4, 4]               [4, 128, 16, 16]       0.95%
│    │    │    │    └─LayerNorm (norm): 5-42            [4, 256, 128]        --                   [4, 256, 128]          0.00%
│    │    │    │    └─Linear (kv): 5-43                 [4, 256, 128]        --                   [4, 256, 256]          0.12%
│    │    │    │    └─Dropout (attn_drop): 5-44         [4, 2, 4096, 256]    --                   [4, 2, 4096, 256]         --
│    │    │    │    └─Linear (proj): 5-45               [4, 4096, 128]       --                   [4, 4096, 128]         0.06%
│    │    │    │    └─Dropout (proj_drop): 5-46         [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    └─DropPath (drop_path): 4-21             [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    └─LayerNorm (norm2): 4-22                [4, 4096, 128]       --                   [4, 4096, 128]         0.00%
│    │    │    └─Mlp (mlp): 4-23                        [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    │    └─Linear (fc1): 5-47                [4, 4096, 128]       --                   [4, 4096, 512]         0.24%
│    │    │    │    └─DWConv (dwconv): 5-48             [4, 4096, 512]       --                   [4, 4096, 512]         0.02%
│    │    │    │    └─GELU (act): 5-49                  [4, 4096, 512]       --                   [4, 4096, 512]            --
│    │    │    │    └─Dropout (drop): 5-50              [4, 4096, 512]       --                   [4, 4096, 512]            --
│    │    │    │    └─Linear (fc2): 5-51                [4, 4096, 512]       --                   [4, 4096, 128]         0.24%
│    │    │    │    └─Dropout (drop): 5-52              [4, 4096, 128]       --                   [4, 4096, 128]       (recursive)
│    │    │    └─DropPath (drop_path): 4-24             [4, 4096, 128]       --                   [4, 4096, 128]       (recursive)
│    │    └─Block (1): 3-9                              [4, 128, 64, 64]     --                   [4, 128, 64, 64]          --
│    │    │    └─LayerNorm (norm1): 4-25                [4, 4096, 128]       --                   [4, 4096, 128]         0.00%
│    │    │    └─Attention (attn): 4-26                 [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    │    └─Linear (q): 5-53                  [4, 4096, 128]       --                   [4, 4096, 128]         0.06%
│    │    │    │    └─Conv2d (sr): 5-54                 [4, 128, 64, 64]     [4, 4]               [4, 128, 16, 16]       0.95%
│    │    │    │    └─LayerNorm (norm): 5-55            [4, 256, 128]        --                   [4, 256, 128]          0.00%
│    │    │    │    └─Linear (kv): 5-56                 [4, 256, 128]        --                   [4, 256, 256]          0.12%
│    │    │    │    └─Dropout (attn_drop): 5-57         [4, 2, 4096, 256]    --                   [4, 2, 4096, 256]         --
│    │    │    │    └─Linear (proj): 5-58               [4, 4096, 128]       --                   [4, 4096, 128]         0.06%
│    │    │    │    └─Dropout (proj_drop): 5-59         [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    └─DropPath (drop_path): 4-27             [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    └─LayerNorm (norm2): 4-28                [4, 4096, 128]       --                   [4, 4096, 128]         0.00%
│    │    │    └─Mlp (mlp): 4-29                        [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    │    └─Linear (fc1): 5-60                [4, 4096, 128]       --                   [4, 4096, 512]         0.24%
│    │    │    │    └─DWConv (dwconv): 5-61             [4, 4096, 512]       --                   [4, 4096, 512]         0.02%
│    │    │    │    └─GELU (act): 5-62                  [4, 4096, 512]       --                   [4, 4096, 512]            --
│    │    │    │    └─Dropout (drop): 5-63              [4, 4096, 512]       --                   [4, 4096, 512]            --
│    │    │    │    └─Linear (fc2): 5-64                [4, 4096, 512]       --                   [4, 4096, 128]         0.24%
│    │    │    │    └─Dropout (drop): 5-65              [4, 4096, 128]       --                   [4, 4096, 128]       (recursive)
│    │    │    └─DropPath (drop_path): 4-30             [4, 4096, 128]       --                   [4, 4096, 128]       (recursive)
│    │    └─Block (2): 3-10                             [4, 128, 64, 64]     --                   [4, 128, 64, 64]          --
│    │    │    └─LayerNorm (norm1): 4-31                [4, 4096, 128]       --                   [4, 4096, 128]         0.00%
│    │    │    └─Attention (attn): 4-32                 [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    │    └─Linear (q): 5-66                  [4, 4096, 128]       --                   [4, 4096, 128]         0.06%
│    │    │    │    └─Conv2d (sr): 5-67                 [4, 128, 64, 64]     [4, 4]               [4, 128, 16, 16]       0.95%
│    │    │    │    └─LayerNorm (norm): 5-68            [4, 256, 128]        --                   [4, 256, 128]          0.00%
│    │    │    │    └─Linear (kv): 5-69                 [4, 256, 128]        --                   [4, 256, 256]          0.12%
│    │    │    │    └─Dropout (attn_drop): 5-70         [4, 2, 4096, 256]    --                   [4, 2, 4096, 256]         --
│    │    │    │    └─Linear (proj): 5-71               [4, 4096, 128]       --                   [4, 4096, 128]         0.06%
│    │    │    │    └─Dropout (proj_drop): 5-72         [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    └─DropPath (drop_path): 4-33             [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    └─LayerNorm (norm2): 4-34                [4, 4096, 128]       --                   [4, 4096, 128]         0.00%
│    │    │    └─Mlp (mlp): 4-35                        [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    │    └─Linear (fc1): 5-73                [4, 4096, 128]       --                   [4, 4096, 512]         0.24%
│    │    │    │    └─DWConv (dwconv): 5-74             [4, 4096, 512]       --                   [4, 4096, 512]         0.02%
│    │    │    │    └─GELU (act): 5-75                  [4, 4096, 512]       --                   [4, 4096, 512]            --
│    │    │    │    └─Dropout (drop): 5-76              [4, 4096, 512]       --                   [4, 4096, 512]            --
│    │    │    │    └─Linear (fc2): 5-77                [4, 4096, 512]       --                   [4, 4096, 128]         0.24%
│    │    │    │    └─Dropout (drop): 5-78              [4, 4096, 128]       --                   [4, 4096, 128]       (recursive)
│    │    │    └─DropPath (drop_path): 4-36             [4, 4096, 128]       --                   [4, 4096, 128]       (recursive)
│    │    └─Block (3): 3-11                             [4, 128, 64, 64]     --                   [4, 128, 64, 64]          --
│    │    │    └─LayerNorm (norm1): 4-37                [4, 4096, 128]       --                   [4, 4096, 128]         0.00%
│    │    │    └─Attention (attn): 4-38                 [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    │    └─Linear (q): 5-79                  [4, 4096, 128]       --                   [4, 4096, 128]         0.06%
│    │    │    │    └─Conv2d (sr): 5-80                 [4, 128, 64, 64]     [4, 4]               [4, 128, 16, 16]       0.95%
│    │    │    │    └─LayerNorm (norm): 5-81            [4, 256, 128]        --                   [4, 256, 128]          0.00%
│    │    │    │    └─Linear (kv): 5-82                 [4, 256, 128]        --                   [4, 256, 256]          0.12%
│    │    │    │    └─Dropout (attn_drop): 5-83         [4, 2, 4096, 256]    --                   [4, 2, 4096, 256]         --
│    │    │    │    └─Linear (proj): 5-84               [4, 4096, 128]       --                   [4, 4096, 128]         0.06%
│    │    │    │    └─Dropout (proj_drop): 5-85         [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    └─DropPath (drop_path): 4-39             [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    └─LayerNorm (norm2): 4-40                [4, 4096, 128]       --                   [4, 4096, 128]         0.00%
│    │    │    └─Mlp (mlp): 4-41                        [4, 4096, 128]       --                   [4, 4096, 128]            --
│    │    │    │    └─Linear (fc1): 5-86                [4, 4096, 128]       --                   [4, 4096, 512]         0.24%
│    │    │    │    └─DWConv (dwconv): 5-87             [4, 4096, 512]       --                   [4, 4096, 512]         0.02%
│    │    │    │    └─GELU (act): 5-88                  [4, 4096, 512]       --                   [4, 4096, 512]            --
│    │    │    │    └─Dropout (drop): 5-89              [4, 4096, 512]       --                   [4, 4096, 512]            --
│    │    │    │    └─Linear (fc2): 5-90                [4, 4096, 512]       --                   [4, 4096, 128]         0.24%
│    │    │    │    └─Dropout (drop): 5-91              [4, 4096, 128]       --                   [4, 4096, 128]       (recursive)
│    │    │    └─DropPath (drop_path): 4-42             [4, 4096, 128]       --                   [4, 4096, 128]       (recursive)
│    └─LayerNorm (norm2): 2-6                           [4, 128, 64, 64]     --                   [4, 128, 64, 64]       0.00%
│    └─OverlapPatchEmbed (patch_embed3): 2-7            [4, 128, 64, 64]     --                   [4, 320, 32, 32]          --
│    │    └─Conv2d (proj): 3-12                         [4, 128, 64, 64]     [3, 3]               [4, 320, 32, 32]       1.34%
│    │    └─LayerNorm (norm): 3-13                      [4, 320, 32, 32]     --                   [4, 320, 32, 32]       0.00%
│    └─Sequential (block3): 2-8                         [4, 320, 32, 32]     --                   [4, 320, 32, 32]          --
│    │    └─Block (0): 3-14                             [4, 320, 32, 32]     --                   [4, 320, 32, 32]          --
│    │    │    └─LayerNorm (norm1): 4-43                [4, 1024, 320]       --                   [4, 1024, 320]         0.00%
│    │    │    └─Attention (attn): 4-44                 [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    │    └─Linear (q): 5-92                  [4, 1024, 320]       --                   [4, 1024, 320]         0.37%
│    │    │    │    └─Conv2d (sr): 5-93                 [4, 320, 32, 32]     [2, 2]               [4, 320, 16, 16]       1.49%
│    │    │    │    └─LayerNorm (norm): 5-94            [4, 256, 320]        --                   [4, 256, 320]          0.00%
│    │    │    │    └─Linear (kv): 5-95                 [4, 256, 320]        --                   [4, 256, 640]          0.75%
│    │    │    │    └─Dropout (attn_drop): 5-96         [4, 5, 1024, 256]    --                   [4, 5, 1024, 256]         --
│    │    │    │    └─Linear (proj): 5-97               [4, 1024, 320]       --                   [4, 1024, 320]         0.37%
│    │    │    │    └─Dropout (proj_drop): 5-98         [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    └─DropPath (drop_path): 4-45             [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    └─LayerNorm (norm2): 4-46                [4, 1024, 320]       --                   [4, 1024, 320]         0.00%
│    │    │    └─Mlp (mlp): 4-47                        [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    │    └─Linear (fc1): 5-99                [4, 1024, 320]       --                   [4, 1024, 1280]        1.50%
│    │    │    │    └─DWConv (dwconv): 5-100            [4, 1024, 1280]      --                   [4, 1024, 1280]        0.05%
│    │    │    │    └─GELU (act): 5-101                 [4, 1024, 1280]      --                   [4, 1024, 1280]           --
│    │    │    │    └─Dropout (drop): 5-102             [4, 1024, 1280]      --                   [4, 1024, 1280]           --
│    │    │    │    └─Linear (fc2): 5-103               [4, 1024, 1280]      --                   [4, 1024, 320]         1.49%
│    │    │    │    └─Dropout (drop): 5-104             [4, 1024, 320]       --                   [4, 1024, 320]       (recursive)
│    │    │    └─DropPath (drop_path): 4-48             [4, 1024, 320]       --                   [4, 1024, 320]       (recursive)
│    │    └─Block (1): 3-15                             [4, 320, 32, 32]     --                   [4, 320, 32, 32]          --
│    │    │    └─LayerNorm (norm1): 4-49                [4, 1024, 320]       --                   [4, 1024, 320]         0.00%
│    │    │    └─Attention (attn): 4-50                 [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    │    └─Linear (q): 5-105                 [4, 1024, 320]       --                   [4, 1024, 320]         0.37%
│    │    │    │    └─Conv2d (sr): 5-106                [4, 320, 32, 32]     [2, 2]               [4, 320, 16, 16]       1.49%
│    │    │    │    └─LayerNorm (norm): 5-107           [4, 256, 320]        --                   [4, 256, 320]          0.00%
│    │    │    │    └─Linear (kv): 5-108                [4, 256, 320]        --                   [4, 256, 640]          0.75%
│    │    │    │    └─Dropout (attn_drop): 5-109        [4, 5, 1024, 256]    --                   [4, 5, 1024, 256]         --
│    │    │    │    └─Linear (proj): 5-110              [4, 1024, 320]       --                   [4, 1024, 320]         0.37%
│    │    │    │    └─Dropout (proj_drop): 5-111        [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    └─DropPath (drop_path): 4-51             [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    └─LayerNorm (norm2): 4-52                [4, 1024, 320]       --                   [4, 1024, 320]         0.00%
│    │    │    └─Mlp (mlp): 4-53                        [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    │    └─Linear (fc1): 5-112               [4, 1024, 320]       --                   [4, 1024, 1280]        1.50%
│    │    │    │    └─DWConv (dwconv): 5-113            [4, 1024, 1280]      --                   [4, 1024, 1280]        0.05%
│    │    │    │    └─GELU (act): 5-114                 [4, 1024, 1280]      --                   [4, 1024, 1280]           --
│    │    │    │    └─Dropout (drop): 5-115             [4, 1024, 1280]      --                   [4, 1024, 1280]           --
│    │    │    │    └─Linear (fc2): 5-116               [4, 1024, 1280]      --                   [4, 1024, 320]         1.49%
│    │    │    │    └─Dropout (drop): 5-117             [4, 1024, 320]       --                   [4, 1024, 320]       (recursive)
│    │    │    └─DropPath (drop_path): 4-54             [4, 1024, 320]       --                   [4, 1024, 320]       (recursive)
│    │    └─Block (2): 3-16                             [4, 320, 32, 32]     --                   [4, 320, 32, 32]          --
│    │    │    └─LayerNorm (norm1): 4-55                [4, 1024, 320]       --                   [4, 1024, 320]         0.00%
│    │    │    └─Attention (attn): 4-56                 [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    │    └─Linear (q): 5-118                 [4, 1024, 320]       --                   [4, 1024, 320]         0.37%
│    │    │    │    └─Conv2d (sr): 5-119                [4, 320, 32, 32]     [2, 2]               [4, 320, 16, 16]       1.49%
│    │    │    │    └─LayerNorm (norm): 5-120           [4, 256, 320]        --                   [4, 256, 320]          0.00%
│    │    │    │    └─Linear (kv): 5-121                [4, 256, 320]        --                   [4, 256, 640]          0.75%
│    │    │    │    └─Dropout (attn_drop): 5-122        [4, 5, 1024, 256]    --                   [4, 5, 1024, 256]         --
│    │    │    │    └─Linear (proj): 5-123              [4, 1024, 320]       --                   [4, 1024, 320]         0.37%
│    │    │    │    └─Dropout (proj_drop): 5-124        [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    └─DropPath (drop_path): 4-57             [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    └─LayerNorm (norm2): 4-58                [4, 1024, 320]       --                   [4, 1024, 320]         0.00%
│    │    │    └─Mlp (mlp): 4-59                        [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    │    └─Linear (fc1): 5-125               [4, 1024, 320]       --                   [4, 1024, 1280]        1.50%
│    │    │    │    └─DWConv (dwconv): 5-126            [4, 1024, 1280]      --                   [4, 1024, 1280]        0.05%
│    │    │    │    └─GELU (act): 5-127                 [4, 1024, 1280]      --                   [4, 1024, 1280]           --
│    │    │    │    └─Dropout (drop): 5-128             [4, 1024, 1280]      --                   [4, 1024, 1280]           --
│    │    │    │    └─Linear (fc2): 5-129               [4, 1024, 1280]      --                   [4, 1024, 320]         1.49%
│    │    │    │    └─Dropout (drop): 5-130             [4, 1024, 320]       --                   [4, 1024, 320]       (recursive)
│    │    │    └─DropPath (drop_path): 4-60             [4, 1024, 320]       --                   [4, 1024, 320]       (recursive)
│    │    └─Block (3): 3-17                             [4, 320, 32, 32]     --                   [4, 320, 32, 32]          --
│    │    │    └─LayerNorm (norm1): 4-61                [4, 1024, 320]       --                   [4, 1024, 320]         0.00%
│    │    │    └─Attention (attn): 4-62                 [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    │    └─Linear (q): 5-131                 [4, 1024, 320]       --                   [4, 1024, 320]         0.37%
│    │    │    │    └─Conv2d (sr): 5-132                [4, 320, 32, 32]     [2, 2]               [4, 320, 16, 16]       1.49%
│    │    │    │    └─LayerNorm (norm): 5-133           [4, 256, 320]        --                   [4, 256, 320]          0.00%
│    │    │    │    └─Linear (kv): 5-134                [4, 256, 320]        --                   [4, 256, 640]          0.75%
│    │    │    │    └─Dropout (attn_drop): 5-135        [4, 5, 1024, 256]    --                   [4, 5, 1024, 256]         --
│    │    │    │    └─Linear (proj): 5-136              [4, 1024, 320]       --                   [4, 1024, 320]         0.37%
│    │    │    │    └─Dropout (proj_drop): 5-137        [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    └─DropPath (drop_path): 4-63             [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    └─LayerNorm (norm2): 4-64                [4, 1024, 320]       --                   [4, 1024, 320]         0.00%
│    │    │    └─Mlp (mlp): 4-65                        [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    │    └─Linear (fc1): 5-138               [4, 1024, 320]       --                   [4, 1024, 1280]        1.50%
│    │    │    │    └─DWConv (dwconv): 5-139            [4, 1024, 1280]      --                   [4, 1024, 1280]        0.05%
│    │    │    │    └─GELU (act): 5-140                 [4, 1024, 1280]      --                   [4, 1024, 1280]           --
│    │    │    │    └─Dropout (drop): 5-141             [4, 1024, 1280]      --                   [4, 1024, 1280]           --
│    │    │    │    └─Linear (fc2): 5-142               [4, 1024, 1280]      --                   [4, 1024, 320]         1.49%
│    │    │    │    └─Dropout (drop): 5-143             [4, 1024, 320]       --                   [4, 1024, 320]       (recursive)
│    │    │    └─DropPath (drop_path): 4-66             [4, 1024, 320]       --                   [4, 1024, 320]       (recursive)
│    │    └─Block (4): 3-18                             [4, 320, 32, 32]     --                   [4, 320, 32, 32]          --
│    │    │    └─LayerNorm (norm1): 4-67                [4, 1024, 320]       --                   [4, 1024, 320]         0.00%
│    │    │    └─Attention (attn): 4-68                 [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    │    └─Linear (q): 5-144                 [4, 1024, 320]       --                   [4, 1024, 320]         0.37%
│    │    │    │    └─Conv2d (sr): 5-145                [4, 320, 32, 32]     [2, 2]               [4, 320, 16, 16]       1.49%
│    │    │    │    └─LayerNorm (norm): 5-146           [4, 256, 320]        --                   [4, 256, 320]          0.00%
│    │    │    │    └─Linear (kv): 5-147                [4, 256, 320]        --                   [4, 256, 640]          0.75%
│    │    │    │    └─Dropout (attn_drop): 5-148        [4, 5, 1024, 256]    --                   [4, 5, 1024, 256]         --
│    │    │    │    └─Linear (proj): 5-149              [4, 1024, 320]       --                   [4, 1024, 320]         0.37%
│    │    │    │    └─Dropout (proj_drop): 5-150        [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    └─DropPath (drop_path): 4-69             [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    └─LayerNorm (norm2): 4-70                [4, 1024, 320]       --                   [4, 1024, 320]         0.00%
│    │    │    └─Mlp (mlp): 4-71                        [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    │    └─Linear (fc1): 5-151               [4, 1024, 320]       --                   [4, 1024, 1280]        1.50%
│    │    │    │    └─DWConv (dwconv): 5-152            [4, 1024, 1280]      --                   [4, 1024, 1280]        0.05%
│    │    │    │    └─GELU (act): 5-153                 [4, 1024, 1280]      --                   [4, 1024, 1280]           --
│    │    │    │    └─Dropout (drop): 5-154             [4, 1024, 1280]      --                   [4, 1024, 1280]           --
│    │    │    │    └─Linear (fc2): 5-155               [4, 1024, 1280]      --                   [4, 1024, 320]         1.49%
│    │    │    │    └─Dropout (drop): 5-156             [4, 1024, 320]       --                   [4, 1024, 320]       (recursive)
│    │    │    └─DropPath (drop_path): 4-72             [4, 1024, 320]       --                   [4, 1024, 320]       (recursive)
│    │    └─Block (5): 3-19                             [4, 320, 32, 32]     --                   [4, 320, 32, 32]          --
│    │    │    └─LayerNorm (norm1): 4-73                [4, 1024, 320]       --                   [4, 1024, 320]         0.00%
│    │    │    └─Attention (attn): 4-74                 [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    │    └─Linear (q): 5-157                 [4, 1024, 320]       --                   [4, 1024, 320]         0.37%
│    │    │    │    └─Conv2d (sr): 5-158                [4, 320, 32, 32]     [2, 2]               [4, 320, 16, 16]       1.49%
│    │    │    │    └─LayerNorm (norm): 5-159           [4, 256, 320]        --                   [4, 256, 320]          0.00%
│    │    │    │    └─Linear (kv): 5-160                [4, 256, 320]        --                   [4, 256, 640]          0.75%
│    │    │    │    └─Dropout (attn_drop): 5-161        [4, 5, 1024, 256]    --                   [4, 5, 1024, 256]         --
│    │    │    │    └─Linear (proj): 5-162              [4, 1024, 320]       --                   [4, 1024, 320]         0.37%
│    │    │    │    └─Dropout (proj_drop): 5-163        [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    └─DropPath (drop_path): 4-75             [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    └─LayerNorm (norm2): 4-76                [4, 1024, 320]       --                   [4, 1024, 320]         0.00%
│    │    │    └─Mlp (mlp): 4-77                        [4, 1024, 320]       --                   [4, 1024, 320]            --
│    │    │    │    └─Linear (fc1): 5-164               [4, 1024, 320]       --                   [4, 1024, 1280]        1.50%
│    │    │    │    └─DWConv (dwconv): 5-165            [4, 1024, 1280]      --                   [4, 1024, 1280]        0.05%
│    │    │    │    └─GELU (act): 5-166                 [4, 1024, 1280]      --                   [4, 1024, 1280]           --
│    │    │    │    └─Dropout (drop): 5-167             [4, 1024, 1280]      --                   [4, 1024, 1280]           --
│    │    │    │    └─Linear (fc2): 5-168               [4, 1024, 1280]      --                   [4, 1024, 320]         1.49%
│    │    │    │    └─Dropout (drop): 5-169             [4, 1024, 320]       --                   [4, 1024, 320]       (recursive)
│    │    │    └─DropPath (drop_path): 4-78             [4, 1024, 320]       --                   [4, 1024, 320]       (recursive)
│    └─LayerNorm (norm3): 2-9                           [4, 320, 32, 32]     --                   [4, 320, 32, 32]       0.00%
│    └─OverlapPatchEmbed (patch_embed4): 2-10           [4, 320, 32, 32]     --                   [4, 512, 16, 16]          --
│    │    └─Conv2d (proj): 3-20                         [4, 320, 32, 32]     [3, 3]               [4, 512, 16, 16]       5.37%
│    │    └─LayerNorm (norm): 3-21                      [4, 512, 16, 16]     --                   [4, 512, 16, 16]       0.00%
│    └─Sequential (block4): 2-11                        [4, 512, 16, 16]     --                   [4, 512, 16, 16]          --
│    │    └─Block (0): 3-22                             [4, 512, 16, 16]     --                   [4, 512, 16, 16]          --
│    │    │    └─LayerNorm (norm1): 4-79                [4, 256, 512]        --                   [4, 256, 512]          0.00%
│    │    │    └─Attention (attn): 4-80                 [4, 256, 512]        --                   [4, 256, 512]             --
│    │    │    │    └─Linear (q): 5-170                 [4, 256, 512]        --                   [4, 256, 512]          0.96%
│    │    │    │    └─Linear (kv): 5-171                [4, 256, 512]        --                   [4, 256, 1024]         1.91%
│    │    │    │    └─Dropout (attn_drop): 5-172        [4, 8, 256, 256]     --                   [4, 8, 256, 256]          --
│    │    │    │    └─Linear (proj): 5-173              [4, 256, 512]        --                   [4, 256, 512]          0.96%
│    │    │    │    └─Dropout (proj_drop): 5-174        [4, 256, 512]        --                   [4, 256, 512]             --
│    │    │    └─DropPath (drop_path): 4-81             [4, 256, 512]        --                   [4, 256, 512]             --
│    │    │    └─LayerNorm (norm2): 4-82                [4, 256, 512]        --                   [4, 256, 512]          0.00%
│    │    │    └─Mlp (mlp): 4-83                        [4, 256, 512]        --                   [4, 256, 512]             --
│    │    │    │    └─Linear (fc1): 5-175               [4, 256, 512]        --                   [4, 256, 2048]         3.82%
│    │    │    │    └─DWConv (dwconv): 5-176            [4, 256, 2048]       --                   [4, 256, 2048]         0.07%
│    │    │    │    └─GELU (act): 5-177                 [4, 256, 2048]       --                   [4, 256, 2048]            --
│    │    │    │    └─Dropout (drop): 5-178             [4, 256, 2048]       --                   [4, 256, 2048]            --
│    │    │    │    └─Linear (fc2): 5-179               [4, 256, 2048]       --                   [4, 256, 512]          3.82%
│    │    │    │    └─Dropout (drop): 5-180             [4, 256, 512]        --                   [4, 256, 512]        (recursive)
│    │    │    └─DropPath (drop_path): 4-84             [4, 256, 512]        --                   [4, 256, 512]        (recursive)
│    │    └─Block (1): 3-23                             [4, 512, 16, 16]     --                   [4, 512, 16, 16]          --
│    │    │    └─LayerNorm (norm1): 4-85                [4, 256, 512]        --                   [4, 256, 512]          0.00%
│    │    │    └─Attention (attn): 4-86                 [4, 256, 512]        --                   [4, 256, 512]             --
│    │    │    │    └─Linear (q): 5-181                 [4, 256, 512]        --                   [4, 256, 512]          0.96%
│    │    │    │    └─Linear (kv): 5-182                [4, 256, 512]        --                   [4, 256, 1024]         1.91%
│    │    │    │    └─Dropout (attn_drop): 5-183        [4, 8, 256, 256]     --                   [4, 8, 256, 256]          --
│    │    │    │    └─Linear (proj): 5-184              [4, 256, 512]        --                   [4, 256, 512]          0.96%
│    │    │    │    └─Dropout (proj_drop): 5-185        [4, 256, 512]        --                   [4, 256, 512]             --
│    │    │    └─DropPath (drop_path): 4-87             [4, 256, 512]        --                   [4, 256, 512]             --
│    │    │    └─LayerNorm (norm2): 4-88                [4, 256, 512]        --                   [4, 256, 512]          0.00%
│    │    │    └─Mlp (mlp): 4-89                        [4, 256, 512]        --                   [4, 256, 512]             --
│    │    │    │    └─Linear (fc1): 5-186               [4, 256, 512]        --                   [4, 256, 2048]         3.82%
│    │    │    │    └─DWConv (dwconv): 5-187            [4, 256, 2048]       --                   [4, 256, 2048]         0.07%
│    │    │    │    └─GELU (act): 5-188                 [4, 256, 2048]       --                   [4, 256, 2048]            --
│    │    │    │    └─Dropout (drop): 5-189             [4, 256, 2048]       --                   [4, 256, 2048]            --
│    │    │    │    └─Linear (fc2): 5-190               [4, 256, 2048]       --                   [4, 256, 512]          3.82%
│    │    │    │    └─Dropout (drop): 5-191             [4, 256, 512]        --                   [4, 256, 512]        (recursive)
│    │    │    └─DropPath (drop_path): 4-90             [4, 256, 512]        --                   [4, 256, 512]        (recursive)
│    │    └─Block (2): 3-24                             [4, 512, 16, 16]     --                   [4, 512, 16, 16]          --
│    │    │    └─LayerNorm (norm1): 4-91                [4, 256, 512]        --                   [4, 256, 512]          0.00%
│    │    │    └─Attention (attn): 4-92                 [4, 256, 512]        --                   [4, 256, 512]             --
│    │    │    │    └─Linear (q): 5-192                 [4, 256, 512]        --                   [4, 256, 512]          0.96%
│    │    │    │    └─Linear (kv): 5-193                [4, 256, 512]        --                   [4, 256, 1024]         1.91%
│    │    │    │    └─Dropout (attn_drop): 5-194        [4, 8, 256, 256]     --                   [4, 8, 256, 256]          --
│    │    │    │    └─Linear (proj): 5-195              [4, 256, 512]        --                   [4, 256, 512]          0.96%
│    │    │    │    └─Dropout (proj_drop): 5-196        [4, 256, 512]        --                   [4, 256, 512]             --
│    │    │    └─DropPath (drop_path): 4-93             [4, 256, 512]        --                   [4, 256, 512]             --
│    │    │    └─LayerNorm (norm2): 4-94                [4, 256, 512]        --                   [4, 256, 512]          0.00%
│    │    │    └─Mlp (mlp): 4-95                        [4, 256, 512]        --                   [4, 256, 512]             --
│    │    │    │    └─Linear (fc1): 5-197               [4, 256, 512]        --                   [4, 256, 2048]         3.82%
│    │    │    │    └─DWConv (dwconv): 5-198            [4, 256, 2048]       --                   [4, 256, 2048]         0.07%
│    │    │    │    └─GELU (act): 5-199                 [4, 256, 2048]       --                   [4, 256, 2048]            --
│    │    │    │    └─Dropout (drop): 5-200             [4, 256, 2048]       --                   [4, 256, 2048]            --
│    │    │    │    └─Linear (fc2): 5-201               [4, 256, 2048]       --                   [4, 256, 512]          3.82%
│    │    │    │    └─Dropout (drop): 5-202             [4, 256, 512]        --                   [4, 256, 512]        (recursive)
│    │    │    └─DropPath (drop_path): 4-96             [4, 256, 512]        --                   [4, 256, 512]        (recursive)
│    └─LayerNorm (norm4): 2-12                          [4, 512, 16, 16]     --                   [4, 512, 16, 16]       0.00%
├─UnetDecoder (decoder): 1-2                            [4, 1, 512, 512]     --                   [4, 16, 512, 512]         --
│    └─Identity (center): 2-13                          [4, 512, 16, 16]     --                   [4, 512, 16, 16]          --
│    └─ModuleList (blocks): 2-14                        --                   --                   --                        --
│    │    └─DecoderBlock (0): 3-25                      [4, 512, 16, 16]     --                   [4, 256, 32, 32]          --
│    │    │    └─Attention (attention1): 4-97           [4, 832, 32, 32]     --                   [4, 832, 32, 32]          --
│    │    │    │    └─Identity (attention): 5-203       [4, 832, 32, 32]     --                   [4, 832, 32, 32]          --
│    │    │    └─Conv2dReLU (conv1): 4-98               [4, 832, 32, 32]     --                   [4, 256, 32, 32]          --
│    │    │    │    └─Conv2d (0): 5-204                 [4, 832, 32, 32]     [3, 3]               [4, 256, 32, 32]       6.98%
│    │    │    │    └─BatchNorm2d (1): 5-205            [4, 256, 32, 32]     --                   [4, 256, 32, 32]       0.00%
│    │    │    │    └─ReLU (2): 5-206                   [4, 256, 32, 32]     --                   [4, 256, 32, 32]          --
│    │    │    └─Conv2dReLU (conv2): 4-99               [4, 256, 32, 32]     --                   [4, 256, 32, 32]          --
│    │    │    │    └─Conv2d (0): 5-207                 [4, 256, 32, 32]     [3, 3]               [4, 256, 32, 32]       2.15%
│    │    │    │    └─BatchNorm2d (1): 5-208            [4, 256, 32, 32]     --                   [4, 256, 32, 32]       0.00%
│    │    │    │    └─ReLU (2): 5-209                   [4, 256, 32, 32]     --                   [4, 256, 32, 32]          --
│    │    │    └─Attention (attention2): 4-100          [4, 256, 32, 32]     --                   [4, 256, 32, 32]          --
│    │    │    │    └─Identity (attention): 5-210       [4, 256, 32, 32]     --                   [4, 256, 32, 32]          --
│    │    └─DecoderBlock (1): 3-26                      [4, 256, 32, 32]     --                   [4, 128, 64, 64]          --
│    │    │    └─Attention (attention1): 4-101          [4, 384, 64, 64]     --                   [4, 384, 64, 64]          --
│    │    │    │    └─Identity (attention): 5-211       [4, 384, 64, 64]     --                   [4, 384, 64, 64]          --
│    │    │    └─Conv2dReLU (conv1): 4-102              [4, 384, 64, 64]     --                   [4, 128, 64, 64]          --
│    │    │    │    └─Conv2d (0): 5-212                 [4, 384, 64, 64]     [3, 3]               [4, 128, 64, 64]       1.61%
│    │    │    │    └─BatchNorm2d (1): 5-213            [4, 128, 64, 64]     --                   [4, 128, 64, 64]       0.00%
│    │    │    │    └─ReLU (2): 5-214                   [4, 128, 64, 64]     --                   [4, 128, 64, 64]          --
│    │    │    └─Conv2dReLU (conv2): 4-103              [4, 128, 64, 64]     --                   [4, 128, 64, 64]          --
│    │    │    │    └─Conv2d (0): 5-215                 [4, 128, 64, 64]     [3, 3]               [4, 128, 64, 64]       0.54%
│    │    │    │    └─BatchNorm2d (1): 5-216            [4, 128, 64, 64]     --                   [4, 128, 64, 64]       0.00%
│    │    │    │    └─ReLU (2): 5-217                   [4, 128, 64, 64]     --                   [4, 128, 64, 64]          --
│    │    │    └─Attention (attention2): 4-104          [4, 128, 64, 64]     --                   [4, 128, 64, 64]          --
│    │    │    │    └─Identity (attention): 5-218       [4, 128, 64, 64]     --                   [4, 128, 64, 64]          --
│    │    └─DecoderBlock (2): 3-27                      [4, 128, 64, 64]     --                   [4, 64, 128, 128]         --
│    │    │    └─Attention (attention1): 4-105          [4, 192, 128, 128]   --                   [4, 192, 128, 128]        --
│    │    │    │    └─Identity (attention): 5-219       [4, 192, 128, 128]   --                   [4, 192, 128, 128]        --
│    │    │    └─Conv2dReLU (conv1): 4-106              [4, 192, 128, 128]   --                   [4, 64, 128, 128]         --
│    │    │    │    └─Conv2d (0): 5-220                 [4, 192, 128, 128]   [3, 3]               [4, 64, 128, 128]      0.40%
│    │    │    │    └─BatchNorm2d (1): 5-221            [4, 64, 128, 128]    --                   [4, 64, 128, 128]      0.00%
│    │    │    │    └─ReLU (2): 5-222                   [4, 64, 128, 128]    --                   [4, 64, 128, 128]         --
│    │    │    └─Conv2dReLU (conv2): 4-107              [4, 64, 128, 128]    --                   [4, 64, 128, 128]         --
│    │    │    │    └─Conv2d (0): 5-223                 [4, 64, 128, 128]    [3, 3]               [4, 64, 128, 128]      0.13%
│    │    │    │    └─BatchNorm2d (1): 5-224            [4, 64, 128, 128]    --                   [4, 64, 128, 128]      0.00%
│    │    │    │    └─ReLU (2): 5-225                   [4, 64, 128, 128]    --                   [4, 64, 128, 128]         --
│    │    │    └─Attention (attention2): 4-108          [4, 64, 128, 128]    --                   [4, 64, 128, 128]         --
│    │    │    │    └─Identity (attention): 5-226       [4, 64, 128, 128]    --                   [4, 64, 128, 128]         --
│    │    └─DecoderBlock (3): 3-28                      [4, 64, 128, 128]    --                   [4, 32, 256, 256]         --
│    │    │    └─Attention (attention1): 4-109          [4, 64, 256, 256]    --                   [4, 64, 256, 256]         --
│    │    │    │    └─Identity (attention): 5-227       [4, 64, 256, 256]    --                   [4, 64, 256, 256]         --
│    │    │    └─Conv2dReLU (conv1): 4-110              [4, 64, 256, 256]    --                   [4, 32, 256, 256]         --
│    │    │    │    └─Conv2d (0): 5-228                 [4, 64, 256, 256]    [3, 3]               [4, 32, 256, 256]      0.07%
│    │    │    │    └─BatchNorm2d (1): 5-229            [4, 32, 256, 256]    --                   [4, 32, 256, 256]      0.00%
│    │    │    │    └─ReLU (2): 5-230                   [4, 32, 256, 256]    --                   [4, 32, 256, 256]         --
│    │    │    └─Conv2dReLU (conv2): 4-111              [4, 32, 256, 256]    --                   [4, 32, 256, 256]         --
│    │    │    │    └─Conv2d (0): 5-231                 [4, 32, 256, 256]    [3, 3]               [4, 32, 256, 256]      0.03%
│    │    │    │    └─BatchNorm2d (1): 5-232            [4, 32, 256, 256]    --                   [4, 32, 256, 256]      0.00%
│    │    │    │    └─ReLU (2): 5-233                   [4, 32, 256, 256]    --                   [4, 32, 256, 256]         --
│    │    │    └─Attention (attention2): 4-112          [4, 32, 256, 256]    --                   [4, 32, 256, 256]         --
│    │    │    │    └─Identity (attention): 5-234       [4, 32, 256, 256]    --                   [4, 32, 256, 256]         --
│    │    └─DecoderBlock (4): 3-29                      [4, 32, 256, 256]    --                   [4, 16, 512, 512]         --
│    │    │    └─Conv2dReLU (conv1): 4-113              [4, 32, 512, 512]    --                   [4, 16, 512, 512]         --
│    │    │    │    └─Conv2d (0): 5-235                 [4, 32, 512, 512]    [3, 3]               [4, 16, 512, 512]      0.02%
│    │    │    │    └─BatchNorm2d (1): 5-236            [4, 16, 512, 512]    --                   [4, 16, 512, 512]      0.00%
│    │    │    │    └─ReLU (2): 5-237                   [4, 16, 512, 512]    --                   [4, 16, 512, 512]         --
│    │    │    └─Conv2dReLU (conv2): 4-114              [4, 16, 512, 512]    --                   [4, 16, 512, 512]         --
│    │    │    │    └─Conv2d (0): 5-238                 [4, 16, 512, 512]    [3, 3]               [4, 16, 512, 512]      0.01%
│    │    │    │    └─BatchNorm2d (1): 5-239            [4, 16, 512, 512]    --                   [4, 16, 512, 512]      0.00%
│    │    │    │    └─ReLU (2): 5-240                   [4, 16, 512, 512]    --                   [4, 16, 512, 512]         --
│    │    │    └─Attention (attention2): 4-115          [4, 16, 512, 512]    --                   [4, 16, 512, 512]         --
│    │    │    │    └─Identity (attention): 5-241       [4, 16, 512, 512]    --                   [4, 16, 512, 512]         --
├─SegmentationHead (segmentation_head): 1-3             [4, 16, 512, 512]    --                   [4, 5, 512, 512]          --
│    └─Conv2d (0): 2-15                                 [4, 16, 512, 512]    [3, 3]               [4, 5, 512, 512]       0.00%
│    └─Identity (1): 2-16                               [4, 5, 512, 512]     --                   [4, 5, 512, 512]          --
│    └─Activation (2): 2-17                             [4, 5, 512, 512]     --                   [4, 5, 512, 512]          --
│    │    └─Identity (activation): 3-30                 [4, 5, 512, 512]     --                   [4, 5, 512, 512]          --
=======================================================================================================================================
Total params: 27,471,317
Trainable params: 27,471,317
Non-trainable params: 0
Total mult-adds (G): 54.98
=======================================================================================================================================
Input size (MB): 4.19
Forward/backward pass size (MB): 4550.82
Params size (MB): 109.89
Estimated Total Size (MB): 4664.90
=======================================================================================================================================